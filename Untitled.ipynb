{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9414c47f-a1ae-4e0e-b25a-2432aa9cc493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "394e2a9e-6c61-42f7-94ef-78f9fddba28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ff5802-7e0d-4492-9ec2-7a731a49e5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32470.000000</td>\n",
       "      <td>32470</td>\n",
       "      <td>32470</td>\n",
       "      <td>32470</td>\n",
       "      <td>32470</td>\n",
       "      <td>32470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28803</td>\n",
       "      <td>26340</td>\n",
       "      <td>25704</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011년 12월 17일 그의 아버지인 김정일이 사망하자 김정은은 일단후계자로서의 ...</td>\n",
       "      <td>{'word': '화순군', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>{'word': '구충곤', 'start_idx': 7, 'end_idx': 9, ...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>94</td>\n",
       "      <td>9534</td>\n",
       "      <td>21620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16234.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9373.425957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8117.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16234.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24351.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32469.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           sentence  \\\n",
       "count   32470.000000                                              32470   \n",
       "unique           NaN                                              28803   \n",
       "top              NaN  2011년 12월 17일 그의 아버지인 김정일이 사망하자 김정은은 일단후계자로서의 ...   \n",
       "freq             NaN                                                  3   \n",
       "mean    16234.500000                                                NaN   \n",
       "std      9373.425957                                                NaN   \n",
       "min         0.000000                                                NaN   \n",
       "25%      8117.250000                                                NaN   \n",
       "50%     16234.500000                                                NaN   \n",
       "75%     24351.750000                                                NaN   \n",
       "max     32469.000000                                                NaN   \n",
       "\n",
       "                                           subject_entity  \\\n",
       "count                                               32470   \n",
       "unique                                              26340   \n",
       "top     {'word': '화순군', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "freq                                                   98   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                            object_entity        label  \\\n",
       "count                                               32470        32470   \n",
       "unique                                              25704           30   \n",
       "top     {'word': '구충곤', 'start_idx': 7, 'end_idx': 9, ...  no_relation   \n",
       "freq                                                   94         9534   \n",
       "mean                                                  NaN          NaN   \n",
       "std                                                   NaN          NaN   \n",
       "min                                                   NaN          NaN   \n",
       "25%                                                   NaN          NaN   \n",
       "50%                                                   NaN          NaN   \n",
       "75%                                                   NaN          NaN   \n",
       "max                                                   NaN          NaN   \n",
       "\n",
       "           source  \n",
       "count       32470  \n",
       "unique          3  \n",
       "top     wikipedia  \n",
       "freq        21620  \n",
       "mean          NaN  \n",
       "std           NaN  \n",
       "min           NaN  \n",
       "25%           NaN  \n",
       "50%           NaN  \n",
       "75%           NaN  \n",
       "max           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7bc50a-26c5-40f0-9d22-abb13f105d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>9867</td>\n",
       "      <td>더불어민주당 이용빈 광산갑 국회의원 예비후보는 23일 오전 7시 송정동 영광통사거리...</td>\n",
       "      <td>{'word': '이용빈', 'start_idx': 7, 'end_idx': 9, ...</td>\n",
       "      <td>{'word': '광산갑', 'start_idx': 11, 'end_idx': 13...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17101</th>\n",
       "      <td>17101</td>\n",
       "      <td>초대 당수 선거에는 전 자유개혁연합 대표 가이후 도시키 전 총리, 전 신생당 당수 ...</td>\n",
       "      <td>{'word': '신생당', 'start_idx': 39, 'end_idx': 41...</td>\n",
       "      <td>{'word': '하타 쓰토무', 'start_idx': 46, 'end_idx':...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13006</th>\n",
       "      <td>13006</td>\n",
       "      <td>지난 2017년 차예련 남편인 주상욱 씨가 '미운오리새끼'에 출연해 두 사람의 연애...</td>\n",
       "      <td>{'word': '차예련', 'start_idx': 9, 'end_idx': 11,...</td>\n",
       "      <td>{'word': '주상욱', 'start_idx': 17, 'end_idx': 19...</td>\n",
       "      <td>per:spouse</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25735</th>\n",
       "      <td>25735</td>\n",
       "      <td>당시 1위였던 SK 와이번스가 2위였던 삼성 라이온즈에게 1위 자리를 내줄 위기에 ...</td>\n",
       "      <td>{'word': '김광현', 'start_idx': 101, 'end_idx': 1...</td>\n",
       "      <td>{'word': 'SK 와이번스', 'start_idx': 8, 'end_idx':...</td>\n",
       "      <td>per:employee_of</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24741</th>\n",
       "      <td>24741</td>\n",
       "      <td>쾰른에서 김나지움을 졸업하였고, 1850년에 베를린으로 상경하여 베를린 훔볼트 대학...</td>\n",
       "      <td>{'word': '훔볼트 대학교', 'start_idx': 40, 'end_idx'...</td>\n",
       "      <td>{'word': '베를린', 'start_idx': 25, 'end_idx': 27...</td>\n",
       "      <td>org:place_of_headquarters</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>9923</td>\n",
       "      <td>2004년 7월 1일에 (구)하나로텔레콤으로 변경하였으며, 2008년 9월 22일에...</td>\n",
       "      <td>{'word': '하나로텔레콤', 'start_idx': 16, 'end_idx':...</td>\n",
       "      <td>{'word': 'SK텔레콤', 'start_idx': 47, 'end_idx': ...</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>1743</td>\n",
       "      <td>강서은 아나운서 퇴사 결정 이유에 대해 KBS 측은 매체에 \"개인 사생활 문제라 확...</td>\n",
       "      <td>{'word': '강서은', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>{'word': '아나운서', 'start_idx': 4, 'end_idx': 7,...</td>\n",
       "      <td>per:title</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>6306</td>\n",
       "      <td>김영삼 전 대통령은 2012년 7월 11일 김문수 새누리당 대선 경선후보의 예방에 ...</td>\n",
       "      <td>{'word': '김문수', 'start_idx': 24, 'end_idx': 26...</td>\n",
       "      <td>{'word': '박근혜', 'start_idx': 47, 'end_idx': 49...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>2550</td>\n",
       "      <td>레드불 유한회사의 소유주인 디트리히 마테시츠는 RB 라이프치히가 독일의 챔피언을 노...</td>\n",
       "      <td>{'word': 'RB 라이프치히', 'start_idx': 26, 'end_idx...</td>\n",
       "      <td>{'word': '레드불 유한회사', 'start_idx': 0, 'end_idx'...</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23723</th>\n",
       "      <td>23723</td>\n",
       "      <td>우하람은 14일 광주광역시 광산구 남부대 시립국제수영장에서 열린 2019 광주세계수...</td>\n",
       "      <td>{'word': '우하람', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>{'word': '다이빙', 'start_idx': 53, 'end_idx': 55...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           sentence  \\\n",
       "9867    9867  더불어민주당 이용빈 광산갑 국회의원 예비후보는 23일 오전 7시 송정동 영광통사거리...   \n",
       "17101  17101  초대 당수 선거에는 전 자유개혁연합 대표 가이후 도시키 전 총리, 전 신생당 당수 ...   \n",
       "13006  13006  지난 2017년 차예련 남편인 주상욱 씨가 '미운오리새끼'에 출연해 두 사람의 연애...   \n",
       "25735  25735  당시 1위였던 SK 와이번스가 2위였던 삼성 라이온즈에게 1위 자리를 내줄 위기에 ...   \n",
       "24741  24741  쾰른에서 김나지움을 졸업하였고, 1850년에 베를린으로 상경하여 베를린 훔볼트 대학...   \n",
       "9923    9923  2004년 7월 1일에 (구)하나로텔레콤으로 변경하였으며, 2008년 9월 22일에...   \n",
       "1743    1743  강서은 아나운서 퇴사 결정 이유에 대해 KBS 측은 매체에 \"개인 사생활 문제라 확...   \n",
       "6306    6306  김영삼 전 대통령은 2012년 7월 11일 김문수 새누리당 대선 경선후보의 예방에 ...   \n",
       "2550    2550  레드불 유한회사의 소유주인 디트리히 마테시츠는 RB 라이프치히가 독일의 챔피언을 노...   \n",
       "23723  23723  우하람은 14일 광주광역시 광산구 남부대 시립국제수영장에서 열린 2019 광주세계수...   \n",
       "\n",
       "                                          subject_entity  \\\n",
       "9867   {'word': '이용빈', 'start_idx': 7, 'end_idx': 9, ...   \n",
       "17101  {'word': '신생당', 'start_idx': 39, 'end_idx': 41...   \n",
       "13006  {'word': '차예련', 'start_idx': 9, 'end_idx': 11,...   \n",
       "25735  {'word': '김광현', 'start_idx': 101, 'end_idx': 1...   \n",
       "24741  {'word': '훔볼트 대학교', 'start_idx': 40, 'end_idx'...   \n",
       "9923   {'word': '하나로텔레콤', 'start_idx': 16, 'end_idx':...   \n",
       "1743   {'word': '강서은', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "6306   {'word': '김문수', 'start_idx': 24, 'end_idx': 26...   \n",
       "2550   {'word': 'RB 라이프치히', 'start_idx': 26, 'end_idx...   \n",
       "23723  {'word': '우하람', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "\n",
       "                                           object_entity  \\\n",
       "9867   {'word': '광산갑', 'start_idx': 11, 'end_idx': 13...   \n",
       "17101  {'word': '하타 쓰토무', 'start_idx': 46, 'end_idx':...   \n",
       "13006  {'word': '주상욱', 'start_idx': 17, 'end_idx': 19...   \n",
       "25735  {'word': 'SK 와이번스', 'start_idx': 8, 'end_idx':...   \n",
       "24741  {'word': '베를린', 'start_idx': 25, 'end_idx': 27...   \n",
       "9923   {'word': 'SK텔레콤', 'start_idx': 47, 'end_idx': ...   \n",
       "1743   {'word': '아나운서', 'start_idx': 4, 'end_idx': 7,...   \n",
       "6306   {'word': '박근혜', 'start_idx': 47, 'end_idx': 49...   \n",
       "2550   {'word': '레드불 유한회사', 'start_idx': 0, 'end_idx'...   \n",
       "23723  {'word': '다이빙', 'start_idx': 53, 'end_idx': 55...   \n",
       "\n",
       "                           label     source  \n",
       "9867                 no_relation   wikitree  \n",
       "17101                no_relation  wikipedia  \n",
       "13006                 per:spouse   wikitree  \n",
       "25735            per:employee_of  wikipedia  \n",
       "24741  org:place_of_headquarters  wikipedia  \n",
       "9923               org:member_of  wikipedia  \n",
       "1743                   per:title   wikitree  \n",
       "6306                 no_relation  wikipedia  \n",
       "2550               org:member_of  wikipedia  \n",
       "23723                no_relation   wikitree  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef6b9102-37cd-4a33-b038-6d862c5b771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\" '비틀즈'\", '조지 해리슨')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, 100)\n",
    "idx = 0\n",
    "train_df.loc[idx]['subject_entity'][1:-1].split(',')[0].split(':')[1], train_df.loc[idx]['object_entity'][1:-1].split(',')[0].split(':')[1].strip()[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8032fc92-cbb9-46fc-a6e7-ca32167b12cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORG', 'PER'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_type_dict = train_df.subject_entity\n",
    "sub_set = set()\n",
    "for d in sub_type_dict:\n",
    "    sub_set.add(eval(d)['type'])\n",
    "sub_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e04611-df76-473b-8410-9455d8f56cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DAT', 'LOC', 'NOH', 'ORG', 'PER', 'POH'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_type_dict = train_df.object_entity\n",
    "obj_set = set()\n",
    "for d in obj_type_dict:\n",
    "    obj_set.add(eval(d)['type'])\n",
    "obj_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4c73bf-d3ed-4749-9847-f246d3511441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfe4740-e147-4bbc-965c-300cf9a577e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./code/')\n",
    "from load_data import preprocessing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85dcfd64-28c3-4bb0-89fe-4bfcf3e4f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = preprocessing_dataset(train_df.loc[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60628eaa-01c0-4526-a00e-dc6fbad0eda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>{'word': '비틀즈', 'start_idx': 24, 'end_idx': 26...</td>\n",
       "      <td>{'word': '조지 해리슨', 'start_idx': 13, 'end_idx':...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>{'word': '민주평화당', 'start_idx': 19, 'end_idx': ...</td>\n",
       "      <td>{'word': '대안신당', 'start_idx': 14, 'end_idx': 1...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence  \\\n",
       "0   0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...   \n",
       "1   1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...   \n",
       "\n",
       "                                      subject_entity  \\\n",
       "0  {'word': '비틀즈', 'start_idx': 24, 'end_idx': 26...   \n",
       "1  {'word': '민주평화당', 'start_idx': 19, 'end_idx': ...   \n",
       "\n",
       "                                       object_entity        label     source  \n",
       "0  {'word': '조지 해리슨', 'start_idx': 13, 'end_idx':...  no_relation  wikipedia  \n",
       "1  {'word': '대안신당', 'start_idx': 14, 'end_idx': 1...  no_relation   wikitree  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75621660-3fd5-4573-b118-f186436783f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bcd1d38-4172-4b29-9778-280c6d2eb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = tokenizer.tokenize(A.loc[0]['subject_entity'] + '[SEP]' +  A.loc[0]['object_entity'], A.loc[0]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d25758d2-3946-4156-9a8f-52226264e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                                0\n",
      "sentence          〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...\n",
      "subject_entity                                                '비틀즈'\n",
      "object_entity                                              '조지 해리슨'\n",
      "label                                                   no_relation\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,    11, 29830,    11,     3,    11,  8373, 14113,  2234,    11,\n",
       "             3,   168, 30985, 14451,  7088,  4586,   169,   793,  8373, 14113,\n",
       "          2234,  2052,  1363,  2088, 29830,  2116, 14879,  2440,  6711,   170,\n",
       "         21406, 26713,  2076, 25145,  5749,   171,  1421,   818,  2073,  4388,\n",
       "          2062,    18,     3,     0,     0,     0,     0,     0,     0],\n",
       "        [    2,    11,  3772,  2139,  2267,  2481,    11,     3,    11,  5605,\n",
       "          2250,  2481,    11,     3,  6409,  2052,  4568,  2179,  6417,  2044,\n",
       "          2315,  2481,   100,  5605,  2250,  2481,   100,  3772,  2139,  2267,\n",
       "          2481,  2052, 16489,   711,  2170, 12827,  2097,  8646,  2481,    12,\n",
       "         15283,    13,  3603,  1528,  2554,  2065,  4538,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A.iloc[0])\n",
    "P = tokenized_dataset(A, tokenizer)\n",
    "P\n",
    "# tokenizer.convert_ids_to_tokens(29830)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4870b07e-7a00-41dc-be16-dd7f6ed678af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8376d814-abbf-4714-8cd2-c9cce40b95b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens= ['PER', 'LOC', 'POH', 'DAT', 'NOH', 'ORG']\n",
    "tokenizer.add_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3446ece4-e979-45b6-86cd-ffa718684f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER', 'LOC', 'POH', 'DAT', 'NOH', 'ORG']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55edd0db-81b6-496c-815e-56e5926deddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_sub_ent = []\n",
    "converted_obj_ent = []\n",
    "subject_entity = []\n",
    "object_entity = []\n",
    "for i,j in zip(train_df['subject_entity'], train_df['object_entity']):\n",
    "    # 1. Dict로 변환\n",
    "    i = eval(i)\n",
    "    j = eval(j)\n",
    "    subject_entity.append(i['word'])\n",
    "    object_entity.append(j['word'])\n",
    "    # 2. Punctuation을 넣은 subject_entity, object_entity 추출\n",
    "    # Rule for subject_entity: @ * type * sub_entity @\n",
    "    # Rule for object_entity: # ^ type ^ sub_entity #\n",
    "    i = ' '.join(['@', '*', i['type'], '*', i['word'], '@'])\n",
    "    j = ' '.join(['#', '^', j['type'], '^', j['word'], '#'])\n",
    "    converted_sub_ent.append(i)\n",
    "    converted_obj_ent.append(j)\n",
    "train_df['subject_entity'] = subject_entity\n",
    "train_df['object_entity'] = object_entity\n",
    "train_df['converted_sub_ent'] = converted_sub_ent\n",
    "train_df['converted_obj_ent'] = converted_obj_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0707734-d877-41d9-afbe-4aa28c0c8f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3066\n"
     ]
    }
   ],
   "source": [
    "sub_dup = []\n",
    "for i in range(len(train_df)):\n",
    "    if train_df.iloc[i].sentence.count(train_df.iloc[i].subject_entity) != 1:\n",
    "        # print(i, train_df.iloc[i].subject_entity, train_df.iloc[i].sentence)\n",
    "        sub_dup.append(i)\n",
    "print(len(sub_dup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f675a918-611e-4965-b017-70f49baf4b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1658년, 샤 자한이 병에 걸리자 그의 아들 아우랑제브는 샤 자한을 아그라 성에 죽을때까지 감금했다.', '샤 자한', 716)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(sub_dup)-1)\n",
    "train_df.iloc[sub_dup[idx]].sentence, train_df.iloc[sub_dup[idx]].subject_entity, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8c28ec9-da5f-4816-9984-7e0ec9a46080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([36, 14, 10, 7], ['@', '*', '&', '#'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = ['@', '*', '&', '#']\n",
    "punc_ids = tokenizer.convert_tokens_to_ids(punc)\n",
    "punc_re = tokenizer.convert_ids_to_tokens(punc_ids)\n",
    "punc_ids, punc_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7158f992-e038-4843-87c7-fac749e8d5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa90f635-953f-488e-9435-be2df104c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torchviz in /opt/conda/lib/python3.8/site-packages (0.0.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from torchviz) (1.7.1)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.8/site-packages (from torchviz) (0.20.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch->torchviz) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch->torchviz) (1.19.2)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  fontconfig fontconfig-config fonts-dejavu-core fonts-liberation libann0\n",
      "  libcairo2 libcdt5 libcgraph6 libdatrie1 libfontconfig1 libfreetype6 libgd3\n",
      "  libgraphite2-3 libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libharfbuzz0b\n",
      "  libice6 libjbig0 liblab-gamut1 libltdl7 libpango-1.0-0 libpangocairo-1.0-0\n",
      "  libpangoft2-1.0-0 libpathplan4 libpixman-1-0 libsm6 libthai-data libthai0\n",
      "  libtiff5 libwebp6 libxaw7 libxcb-render0 libxcb-shm0 libxmu6 libxpm4\n",
      "  libxrender1 libxt6 x11-common\n",
      "Suggested packages:\n",
      "  gsfonts graphviz-doc libgd-tools\n",
      "The following NEW packages will be installed:\n",
      "  fontconfig fontconfig-config fonts-dejavu-core fonts-liberation graphviz\n",
      "  libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libfontconfig1 libfreetype6\n",
      "  libgd3 libgraphite2-3 libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libharfbuzz0b\n",
      "  libice6 libjbig0 liblab-gamut1 libltdl7 libpango-1.0-0 libpangocairo-1.0-0\n",
      "  libpangoft2-1.0-0 libpathplan4 libpixman-1-0 libsm6 libthai-data libthai0\n",
      "  libtiff5 libwebp6 libxaw7 libxcb-render0 libxcb-shm0 libxmu6 libxpm4\n",
      "  libxrender1 libxt6 x11-common\n",
      "0 upgraded, 41 newly installed, 0 to remove and 109 not upgraded.\n",
      "Need to get 6958 kB of archives.\n",
      "After this operation, 24.6 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libfreetype6 amd64 2.8.1-2ubuntu2.2 [335 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1041 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 fonts-liberation all 1:1.07.4-7~18.04.1 [822 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig-config all 2.12.6-0ubuntu2 [55.8 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontconfig1 amd64 2.12.6-0ubuntu2 [137 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 x11-common all 1:7.7+19ubuntu7.1 [22.5 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libice6 amd64 2:1.0.9-2ubuntu0.18.04.1 [40.7 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsm6 amd64 2:1.2.2-1 [15.8 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libann0 amd64 1.1.2+doc-6 [24.8 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcdt5 amd64 2.40.1-2 [19.6 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcgraph6 amd64 2.40.1-2 [40.8 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjbig0 amd64 2.1-3.1ubuntu0.18.04.1 [27.0 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtiff5 amd64 4.0.9-5ubuntu0.10 [154 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwebp6 amd64 0.6.1-2ubuntu0.18.04.1 [186 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxpm4 amd64 1:3.5.12-1ubuntu0.18.04.2 [34.8 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgd3 amd64 2.2.5-4ubuntu0.5 [119 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4 [150 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpixman-1-0 amd64 0.34.0-2ubuntu0.1 [229 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-render0 amd64 1.13-2~ubuntu18.04 [14.7 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0 amd64 1.13-2~ubuntu18.04 [5600 B]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrender1 amd64 1:0.9.10-1 [18.7 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2 amd64 1.15.10-2ubuntu0.1 [580 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libltdl7 amd64 2.4.6-2 [38.8 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgraphite2-3 amd64 1.3.11-2 [78.7 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libharfbuzz0b amd64 1.7.2-1ubuntu1 [232 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpathplan4 amd64 2.40.1-2 [22.6 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6 amd64 2.40.1-2 [601 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvpr2 amd64 2.40.1-2 [169 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblab-gamut1 amd64 2.40.1-2 [178 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu6 amd64 2:1.1.2-2 [46.0 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 graphviz amd64 2.40.1-2 [601 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-bin amd64 0.7.6+darcs121130-4 [41.3 kB]\n",
      "Fetched 6958 kB in 10s (708 kB/s)                                              \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "(Reading database ... 17022 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libfreetype6_2.8.1-2ubuntu2.2_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.8.1-2ubuntu2.2) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fonts-liberation.\n",
      "Preparing to unpack .../02-fonts-liberation_1%3a1.07.4-7~18.04.1_all.deb ...\n",
      "Unpacking fonts-liberation (1:1.07.4-7~18.04.1) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../03-fontconfig-config_2.12.6-0ubuntu2_all.deb ...\n",
      "Unpacking fontconfig-config (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../04-libfontconfig1_2.12.6-0ubuntu2_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package fontconfig.\n",
      "Preparing to unpack .../05-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
      "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package x11-common.\n",
      "Preparing to unpack .../06-x11-common_1%3a7.7+19ubuntu7.1_all.deb ...\n",
      "dpkg-query: no packages found matching nux-tools\n",
      "Unpacking x11-common (1:7.7+19ubuntu7.1) ...\n",
      "Selecting previously unselected package libice6:amd64.\n",
      "Preparing to unpack .../07-libice6_2%3a1.0.9-2ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libice6:amd64 (2:1.0.9-2ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libsm6:amd64.\n",
      "Preparing to unpack .../08-libsm6_2%3a1.2.2-1_amd64.deb ...\n",
      "Unpacking libsm6:amd64 (2:1.2.2-1) ...\n",
      "Selecting previously unselected package libann0.\n",
      "Preparing to unpack .../09-libann0_1.1.2+doc-6_amd64.deb ...\n",
      "Unpacking libann0 (1.1.2+doc-6) ...\n",
      "Selecting previously unselected package libcdt5.\n",
      "Preparing to unpack .../10-libcdt5_2.40.1-2_amd64.deb ...\n",
      "Unpacking libcdt5 (2.40.1-2) ...\n",
      "Selecting previously unselected package libcgraph6.\n",
      "Preparing to unpack .../11-libcgraph6_2.40.1-2_amd64.deb ...\n",
      "Unpacking libcgraph6 (2.40.1-2) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../12-libjbig0_2.1-3.1ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-3.1ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libtiff5:amd64.\n",
      "Preparing to unpack .../13-libtiff5_4.0.9-5ubuntu0.10_amd64.deb ...\n",
      "Unpacking libtiff5:amd64 (4.0.9-5ubuntu0.10) ...\n",
      "Selecting previously unselected package libwebp6:amd64.\n",
      "Preparing to unpack .../14-libwebp6_0.6.1-2ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libwebp6:amd64 (0.6.1-2ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libxpm4:amd64.\n",
      "Preparing to unpack .../15-libxpm4_1%3a3.5.12-1ubuntu0.18.04.2_amd64.deb ...\n",
      "Unpacking libxpm4:amd64 (1:3.5.12-1ubuntu0.18.04.2) ...\n",
      "Selecting previously unselected package libgd3:amd64.\n",
      "Preparing to unpack .../16-libgd3_2.2.5-4ubuntu0.5_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.5) ...\n",
      "Selecting previously unselected package libgts-0.7-5:amd64.\n",
      "Preparing to unpack .../17-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\n",
      "Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
      "Selecting previously unselected package libpixman-1-0:amd64.\n",
      "Preparing to unpack .../18-libpixman-1-0_0.34.0-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpixman-1-0:amd64 (0.34.0-2ubuntu0.1) ...\n",
      "Selecting previously unselected package libxcb-render0:amd64.\n",
      "Preparing to unpack .../19-libxcb-render0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-render0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxcb-shm0:amd64.\n",
      "Preparing to unpack .../20-libxcb-shm0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-shm0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../21-libxrender1_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Selecting previously unselected package libcairo2:amd64.\n",
      "Preparing to unpack .../22-libcairo2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libcairo2:amd64 (1.15.10-2ubuntu0.1) ...\n",
      "Selecting previously unselected package libltdl7:amd64.\n",
      "Preparing to unpack .../23-libltdl7_2.4.6-2_amd64.deb ...\n",
      "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
      "Selecting previously unselected package libthai-data.\n",
      "Preparing to unpack .../24-libthai-data_0.1.27-2_all.deb ...\n",
      "Unpacking libthai-data (0.1.27-2) ...\n",
      "Selecting previously unselected package libdatrie1:amd64.\n",
      "Preparing to unpack .../25-libdatrie1_0.2.10-7_amd64.deb ...\n",
      "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
      "Selecting previously unselected package libthai0:amd64.\n",
      "Preparing to unpack .../26-libthai0_0.1.27-2_amd64.deb ...\n",
      "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
      "Selecting previously unselected package libpango-1.0-0:amd64.\n",
      "Preparing to unpack .../27-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libgraphite2-3:amd64.\n",
      "Preparing to unpack .../28-libgraphite2-3_1.3.11-2_amd64.deb ...\n",
      "Unpacking libgraphite2-3:amd64 (1.3.11-2) ...\n",
      "Selecting previously unselected package libharfbuzz0b:amd64.\n",
      "Preparing to unpack .../29-libharfbuzz0b_1.7.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking libharfbuzz0b:amd64 (1.7.2-1ubuntu1) ...\n",
      "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
      "Preparing to unpack .../30-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
      "Preparing to unpack .../31-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libpathplan4.\n",
      "Preparing to unpack .../32-libpathplan4_2.40.1-2_amd64.deb ...\n",
      "Unpacking libpathplan4 (2.40.1-2) ...\n",
      "Selecting previously unselected package libgvc6.\n",
      "Preparing to unpack .../33-libgvc6_2.40.1-2_amd64.deb ...\n",
      "Unpacking libgvc6 (2.40.1-2) ...\n",
      "Selecting previously unselected package libgvpr2.\n",
      "Preparing to unpack .../34-libgvpr2_2.40.1-2_amd64.deb ...\n",
      "Unpacking libgvpr2 (2.40.1-2) ...\n",
      "Selecting previously unselected package liblab-gamut1.\n",
      "Preparing to unpack .../35-liblab-gamut1_2.40.1-2_amd64.deb ...\n",
      "Unpacking liblab-gamut1 (2.40.1-2) ...\n",
      "Selecting previously unselected package libxt6:amd64.\n",
      "Preparing to unpack .../36-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
      "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
      "Selecting previously unselected package libxmu6:amd64.\n",
      "Preparing to unpack .../37-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
      "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
      "Selecting previously unselected package libxaw7:amd64.\n",
      "Preparing to unpack .../38-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
      "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
      "Selecting previously unselected package graphviz.\n",
      "Preparing to unpack .../39-graphviz_2.40.1-2_amd64.deb ...\n",
      "Unpacking graphviz (2.40.1-2) ...\n",
      "Selecting previously unselected package libgts-bin.\n",
      "Preparing to unpack .../40-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\n",
      "Unpacking libgts-bin (0.7.6+darcs121130-4) ...\n",
      "Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
      "Setting up libpathplan4 (2.40.1-2) ...\n",
      "Setting up liblab-gamut1 (2.40.1-2) ...\n",
      "Setting up libxcb-render0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libjbig0:amd64 (2.1-3.1ubuntu0.18.04.1) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
      "Setting up libtiff5:amd64 (4.0.9-5ubuntu0.10) ...\n",
      "Setting up fonts-liberation (1:1.07.4-7~18.04.1) ...\n",
      "Setting up libfreetype6:amd64 (2.8.1-2ubuntu2.2) ...\n",
      "Setting up libgraphite2-3:amd64 (1.3.11-2) ...\n",
      "Setting up libpixman-1-0:amd64 (0.34.0-2ubuntu0.1) ...\n",
      "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
      "Setting up libann0 (1.1.2+doc-6) ...\n",
      "Setting up libxcb-shm0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libxpm4:amd64 (1:3.5.12-1ubuntu0.18.04.2) ...\n",
      "Setting up libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Setting up libgts-bin (0.7.6+darcs121130-4) ...\n",
      "Setting up libthai-data (0.1.27-2) ...\n",
      "Setting up x11-common (1:7.7+19ubuntu7.1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up libcdt5 (2.40.1-2) ...\n",
      "Setting up libcgraph6 (2.40.1-2) ...\n",
      "Setting up libwebp6:amd64 (0.6.1-2ubuntu0.18.04.1) ...\n",
      "Setting up fontconfig-config (2.12.6-0ubuntu2) ...\n",
      "Setting up libgvpr2 (2.40.1-2) ...\n",
      "Setting up libharfbuzz0b:amd64 (1.7.2-1ubuntu1) ...\n",
      "Setting up libthai0:amd64 (0.1.27-2) ...\n",
      "Setting up libice6:amd64 (2:1.0.9-2ubuntu0.18.04.1) ...\n",
      "Setting up libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\n",
      "Setting up libsm6:amd64 (2:1.2.2-1) ...\n",
      "Setting up libgd3:amd64 (2.2.5-4ubuntu0.5) ...\n",
      "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
      "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
      "Regenerating fonts cache... done.\n",
      "Setting up libcairo2:amd64 (1.15.10-2ubuntu0.1) ...\n",
      "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
      "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
      "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up libgvc6 (2.40.1-2) ...\n",
      "Setting up graphviz (2.40.1-2) ...\n",
      "Processing triggers for systemd (237-3ubuntu10.52) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n"
     ]
    }
   ],
   "source": [
    "! pip install torchviz\n",
    "! apt-get install -y graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4f94def-0776-4a62-815a-2e1fe26e0de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoModel\n",
    "model = AutoModel.from_pretrained('klue/bert-base')\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d01c000-acbf-45ad-a89d-762386ff8a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 49])\n",
      "torch.Size([2, 49, 768])\n",
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.6053, -0.3736, -0.9977,  ..., -0.2067, -0.5580, -0.6515],\n",
      "         [ 0.6068, -1.2338, -0.8952,  ...,  1.1734, -1.5383, -0.7564],\n",
      "         [ 0.1603,  0.6157, -0.0919,  ...,  0.0046,  0.0810,  0.0345],\n",
      "         ...,\n",
      "         [ 0.7717,  0.3596,  0.4415,  ..., -0.6276,  0.2864,  0.4533],\n",
      "         [ 1.1274,  0.4441,  0.5695,  ..., -0.7828,  0.2426,  0.5054],\n",
      "         [ 0.9771,  0.4549,  0.6015,  ..., -0.6962,  0.1574,  0.2593]],\n",
      "\n",
      "        [[-0.4870, -0.4316, -1.8333,  ..., -0.5860, -0.5443, -0.4812],\n",
      "         [-0.1631, -1.3618, -0.5219,  ...,  1.0423, -1.6355, -1.3724],\n",
      "         [ 0.2783, -0.8193, -1.2071,  ..., -0.0050,  0.2875, -1.0008],\n",
      "         ...,\n",
      "         [-0.9554,  0.3993, -0.2746,  ...,  1.4265, -0.1705, -1.4434],\n",
      "         [ 0.0959, -0.2875, -0.5275,  ..., -0.7850, -0.0365,  0.5177],\n",
      "         [ 0.1108, -0.2736, -0.5189,  ..., -0.7988, -0.0405,  0.5474]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-0.0385,  0.3140, -0.3305,  ...,  0.1337,  0.0445, -0.9575],\n",
      "        [-0.0062, -0.0804,  0.0388,  ..., -0.3820, -0.0243,  0.9175]],\n",
      "       grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "out = model(P['input_ids'])\n",
    "print(P['input_ids'].shape)\n",
    "print(out['last_hidden_state'].shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225a7ec-0377-4d38-8271-0a31cb13522b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
