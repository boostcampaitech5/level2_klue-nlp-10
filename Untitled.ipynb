{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9414c47f-a1ae-4e0e-b25a-2432aa9cc493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394e2a9e-6c61-42f7-94ef-78f9fddba28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ff5802-7e0d-4492-9ec2-7a731a49e5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32470.000000</td>\n",
       "      <td>32470</td>\n",
       "      <td>32470</td>\n",
       "      <td>32470</td>\n",
       "      <td>32470</td>\n",
       "      <td>32470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28803</td>\n",
       "      <td>26340</td>\n",
       "      <td>25704</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>도쿠가와 이에야스와 도쿠가와 히데타다가 20년에 걸쳐 안정시킨 막부를 이어받은 3대...</td>\n",
       "      <td>{'word': '화순군', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>{'word': '구충곤', 'start_idx': 7, 'end_idx': 9, ...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>94</td>\n",
       "      <td>9534</td>\n",
       "      <td>21620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16234.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9373.425957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8117.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16234.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24351.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32469.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           sentence   \n",
       "count   32470.000000                                              32470  \\\n",
       "unique           NaN                                              28803   \n",
       "top              NaN  도쿠가와 이에야스와 도쿠가와 히데타다가 20년에 걸쳐 안정시킨 막부를 이어받은 3대...   \n",
       "freq             NaN                                                  3   \n",
       "mean    16234.500000                                                NaN   \n",
       "std      9373.425957                                                NaN   \n",
       "min         0.000000                                                NaN   \n",
       "25%      8117.250000                                                NaN   \n",
       "50%     16234.500000                                                NaN   \n",
       "75%     24351.750000                                                NaN   \n",
       "max     32469.000000                                                NaN   \n",
       "\n",
       "                                           subject_entity   \n",
       "count                                               32470  \\\n",
       "unique                                              26340   \n",
       "top     {'word': '화순군', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "freq                                                   98   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                            object_entity        label   \n",
       "count                                               32470        32470  \\\n",
       "unique                                              25704           30   \n",
       "top     {'word': '구충곤', 'start_idx': 7, 'end_idx': 9, ...  no_relation   \n",
       "freq                                                   94         9534   \n",
       "mean                                                  NaN          NaN   \n",
       "std                                                   NaN          NaN   \n",
       "min                                                   NaN          NaN   \n",
       "25%                                                   NaN          NaN   \n",
       "50%                                                   NaN          NaN   \n",
       "75%                                                   NaN          NaN   \n",
       "max                                                   NaN          NaN   \n",
       "\n",
       "           source  \n",
       "count       32470  \n",
       "unique          3  \n",
       "top     wikipedia  \n",
       "freq        21620  \n",
       "mean          NaN  \n",
       "std           NaN  \n",
       "min           NaN  \n",
       "25%           NaN  \n",
       "50%           NaN  \n",
       "75%           NaN  \n",
       "max           NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7bc50a-26c5-40f0-9d22-abb13f105d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10256</th>\n",
       "      <td>10256</td>\n",
       "      <td>채태인(蔡泰仁, 1982년 10월 11일 ~)은 전 KBO 리그 SK 와이번스의 내...</td>\n",
       "      <td>{'word': 'KBO 리그', 'start_idx': 29, 'end_idx':...</td>\n",
       "      <td>{'word': '1982년', 'start_idx': 9, 'end_idx': 1...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>5499</td>\n",
       "      <td>2010년 10월 1일 아마추어 스타크래프트 게임단을 운영했던 강동훈 감독이 전 스...</td>\n",
       "      <td>{'word': '안상원', 'start_idx': 67, 'end_idx': 69...</td>\n",
       "      <td>{'word': '스타크래프트 II', 'start_idx': 82, 'end_id...</td>\n",
       "      <td>per:employee_of</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17509</th>\n",
       "      <td>17509</td>\n",
       "      <td>신청자격은 중소벤처기업부에서 시행하는 문화관광형시장 육성사업이나 지역 선도형시장 육...</td>\n",
       "      <td>{'word': '소상공인시장진흥공단', 'start_idx': 86, 'end_i...</td>\n",
       "      <td>{'word': '중소벤처기업부', 'start_idx': 6, 'end_idx':...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21716</th>\n",
       "      <td>21716</td>\n",
       "      <td>정세균 국무총리가 15일 오후 서울 종로구 정부서울청사에서 열린 긴급 중앙재난안전대...</td>\n",
       "      <td>{'word': '정세균', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>{'word': '서울 종로구', 'start_idx': 17, 'end_idx':...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>policy_briefing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17917</th>\n",
       "      <td>17917</td>\n",
       "      <td>김수환, 지학순, 함세웅 등은 천주교 측 지도자로 활동한 반면 그는 윤보선, 함석헌...</td>\n",
       "      <td>{'word': '장준하', 'start_idx': 48, 'end_idx': 50...</td>\n",
       "      <td>{'word': '윤보선', 'start_idx': 38, 'end_idx': 40...</td>\n",
       "      <td>per:colleagues</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29658</th>\n",
       "      <td>29658</td>\n",
       "      <td>모리 시게오(1906년 3월 18일 ~ 1977년 6월 24일)는 일본의 전 프로 ...</td>\n",
       "      <td>{'word': '모리 시게오', 'start_idx': 0, 'end_idx': ...</td>\n",
       "      <td>{'word': '1977년', 'start_idx': 22, 'end_idx': ...</td>\n",
       "      <td>per:date_of_death</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13014</th>\n",
       "      <td>13014</td>\n",
       "      <td>김기창 화백의 딸을 며느리로 맞아 김 화백과는 사돈지간이며 대한민국 해군 제독을 지...</td>\n",
       "      <td>{'word': '손원일', 'start_idx': 48, 'end_idx': 50...</td>\n",
       "      <td>{'word': '대한민국 해군', 'start_idx': 33, 'end_idx'...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25420</th>\n",
       "      <td>25420</td>\n",
       "      <td>2009 미국 여자 프로 축구 시즌에서 6골, 도움 4개를 기록한 에니올라 알루코는...</td>\n",
       "      <td>{'word': '에니올라 알루코', 'start_idx': 37, 'end_idx...</td>\n",
       "      <td>{'word': '잉글랜드', 'start_idx': 105, 'end_idx': ...</td>\n",
       "      <td>per:origin</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11037</th>\n",
       "      <td>11037</td>\n",
       "      <td>포천시인재장학재단(이사장 박윤국)은 지난 23일 포천반월아트홀 대공연장에서 고등학생...</td>\n",
       "      <td>{'word': '포천시인재장학재단', 'start_idx': 87, 'end_id...</td>\n",
       "      <td>{'word': '박윤국', 'start_idx': 14, 'end_idx': 16...</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22770</th>\n",
       "      <td>22770</td>\n",
       "      <td>이재현은 설탕으로 시작한 기업을 변화시키기 위해 '제일제당'에서 'CJ'로 사명을 ...</td>\n",
       "      <td>{'word': 'CJ제일제당', 'start_idx': 60, 'end_idx':...</td>\n",
       "      <td>{'word': '이재현', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           sentence   \n",
       "10256  10256  채태인(蔡泰仁, 1982년 10월 11일 ~)은 전 KBO 리그 SK 와이번스의 내...  \\\n",
       "5499    5499  2010년 10월 1일 아마추어 스타크래프트 게임단을 운영했던 강동훈 감독이 전 스...   \n",
       "17509  17509  신청자격은 중소벤처기업부에서 시행하는 문화관광형시장 육성사업이나 지역 선도형시장 육...   \n",
       "21716  21716  정세균 국무총리가 15일 오후 서울 종로구 정부서울청사에서 열린 긴급 중앙재난안전대...   \n",
       "17917  17917  김수환, 지학순, 함세웅 등은 천주교 측 지도자로 활동한 반면 그는 윤보선, 함석헌...   \n",
       "29658  29658  모리 시게오(1906년 3월 18일 ~ 1977년 6월 24일)는 일본의 전 프로 ...   \n",
       "13014  13014  김기창 화백의 딸을 며느리로 맞아 김 화백과는 사돈지간이며 대한민국 해군 제독을 지...   \n",
       "25420  25420  2009 미국 여자 프로 축구 시즌에서 6골, 도움 4개를 기록한 에니올라 알루코는...   \n",
       "11037  11037  포천시인재장학재단(이사장 박윤국)은 지난 23일 포천반월아트홀 대공연장에서 고등학생...   \n",
       "22770  22770  이재현은 설탕으로 시작한 기업을 변화시키기 위해 '제일제당'에서 'CJ'로 사명을 ...   \n",
       "\n",
       "                                          subject_entity   \n",
       "10256  {'word': 'KBO 리그', 'start_idx': 29, 'end_idx':...  \\\n",
       "5499   {'word': '안상원', 'start_idx': 67, 'end_idx': 69...   \n",
       "17509  {'word': '소상공인시장진흥공단', 'start_idx': 86, 'end_i...   \n",
       "21716  {'word': '정세균', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "17917  {'word': '장준하', 'start_idx': 48, 'end_idx': 50...   \n",
       "29658  {'word': '모리 시게오', 'start_idx': 0, 'end_idx': ...   \n",
       "13014  {'word': '손원일', 'start_idx': 48, 'end_idx': 50...   \n",
       "25420  {'word': '에니올라 알루코', 'start_idx': 37, 'end_idx...   \n",
       "11037  {'word': '포천시인재장학재단', 'start_idx': 87, 'end_id...   \n",
       "22770  {'word': 'CJ제일제당', 'start_idx': 60, 'end_idx':...   \n",
       "\n",
       "                                           object_entity   \n",
       "10256  {'word': '1982년', 'start_idx': 9, 'end_idx': 1...  \\\n",
       "5499   {'word': '스타크래프트 II', 'start_idx': 82, 'end_id...   \n",
       "17509  {'word': '중소벤처기업부', 'start_idx': 6, 'end_idx':...   \n",
       "21716  {'word': '서울 종로구', 'start_idx': 17, 'end_idx':...   \n",
       "17917  {'word': '윤보선', 'start_idx': 38, 'end_idx': 40...   \n",
       "29658  {'word': '1977년', 'start_idx': 22, 'end_idx': ...   \n",
       "13014  {'word': '대한민국 해군', 'start_idx': 33, 'end_idx'...   \n",
       "25420  {'word': '잉글랜드', 'start_idx': 105, 'end_idx': ...   \n",
       "11037  {'word': '박윤국', 'start_idx': 14, 'end_idx': 16...   \n",
       "22770  {'word': '이재현', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "\n",
       "                           label           source  \n",
       "10256                no_relation        wikipedia  \n",
       "5499             per:employee_of        wikipedia  \n",
       "17509                no_relation         wikitree  \n",
       "21716                no_relation  policy_briefing  \n",
       "17917             per:colleagues        wikipedia  \n",
       "29658          per:date_of_death        wikipedia  \n",
       "13014                no_relation        wikipedia  \n",
       "25420                 per:origin        wikipedia  \n",
       "11037  org:top_members/employees         wikitree  \n",
       "22770  org:top_members/employees        wikipedia  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6b9102-37cd-4a33-b038-6d862c5b771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\" '비틀즈'\", '조지 해리슨')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, 100)\n",
    "idx = 0\n",
    "train_df.loc[idx]['subject_entity'][1:-1].split(',')[0].split(':')[1], train_df.loc[idx]['object_entity'][1:-1].split(',')[0].split(':')[1].strip()[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8032fc92-cbb9-46fc-a6e7-ca32167b12cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORG', 'PER'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_type_dict = train_df.subject_entity\n",
    "sub_set = set()\n",
    "for d in sub_type_dict:\n",
    "    sub_set.add(eval(d)['type'])\n",
    "sub_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e04611-df76-473b-8410-9455d8f56cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DAT', 'LOC', 'NOH', 'ORG', 'PER', 'POH'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_type_dict = train_df.object_entity\n",
    "obj_set = set()\n",
    "for d in obj_type_dict:\n",
    "    obj_set.add(eval(d)['type'])\n",
    "obj_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4c73bf-d3ed-4749-9847-f246d3511441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccfe4740-e147-4bbc-965c-300cf9a577e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./code/')\n",
    "import load_data_only_marker\n",
    "from load_data_only_marker import preprocessing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85dcfd64-28c3-4bb0-89fe-4bfcf3e4f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(load_data_only_marker)\n",
    "A = preprocessing_dataset(train_df.loc[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11cf984e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>sub_type</th>\n",
       "      <th>obj_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>비틀즈</td>\n",
       "      <td>조지 해리슨</td>\n",
       "      <td>ORG</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>민주평화당</td>\n",
       "      <td>대안신당</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence subject_entity   \n",
       "0   0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...            비틀즈  \\\n",
       "1   1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...          민주평화당   \n",
       "\n",
       "  object_entity sub_type obj_type        label  \n",
       "0        조지 해리슨      ORG      PER  no_relation  \n",
       "1          대안신당      ORG      ORG  no_relation  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58fe4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 〈 Something 〉 는 # 조지 해리슨 # 이 쓰고 @ 비틀즈 @ 가 1969년 앨범 《 Abbey Road 》 에 담은 노래다. [SEP] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "k = load_data_only_marker.tokenized_dataset(A, tokenizer)\n",
    "print(tokenizer.decode(k.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60628eaa-01c0-4526-a00e-dc6fbad0eda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>{'word': '비틀즈', 'start_idx': 24, 'end_idx': 26...</td>\n",
       "      <td>{'word': '조지 해리슨', 'start_idx': 13, 'end_idx':...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>{'word': '민주평화당', 'start_idx': 19, 'end_idx': ...</td>\n",
       "      <td>{'word': '대안신당', 'start_idx': 14, 'end_idx': 1...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence   \n",
       "0   0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...  \\\n",
       "1   1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...   \n",
       "\n",
       "                                      subject_entity   \n",
       "0  {'word': '비틀즈', 'start_idx': 24, 'end_idx': 26...  \\\n",
       "1  {'word': '민주평화당', 'start_idx': 19, 'end_idx': ...   \n",
       "\n",
       "                                       object_entity        label     source  \n",
       "0  {'word': '조지 해리슨', 'start_idx': 13, 'end_idx':...  no_relation  wikipedia  \n",
       "1  {'word': '대안신당', 'start_idx': 14, 'end_idx': 1...  no_relation   wikitree  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd1d38-4172-4b29-9778-280c6d2eb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = tokenizer.tokenize(A.loc[0]['subject_entity'] + '[SEP]' +  A.loc[0]['object_entity'], A.loc[0]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e30f5bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,   168, 30985, 14451,  7088,  4586,   169,   793,     7,  8373,\n",
       "         14113,  2234,     7,  1504,  1363,  2088,    36, 29830,    36,   543,\n",
       "         14879,  2440,  6711,   170, 21406, 26713,  2076, 25145,  5749,   171,\n",
       "          1421,   818,  2073,  4388,  2062,    18,     3,     0,     0,     0],\n",
       "        [    2,  6409,  2052,  4568,  2179,  6417,  2044,  2315,  2481,   100,\n",
       "             7,  5605,  2250,  2481,     7,   100,    36,  3772,  2139,  2267,\n",
       "          2481,    36,  1504, 16489,   711,  2170, 12827,  2097,  8646,  2481,\n",
       "            12, 15283,    13,  3603,  1528,  2554,  2065,  4538,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4870b07e-7a00-41dc-be16-dd7f6ed678af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8376d814-abbf-4714-8cd2-c9cce40b95b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens= ['PER', 'LOC', 'POH', 'DAT', 'NOH', 'ORG']\n",
    "tokenizer.add_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3446ece4-e979-45b6-86cd-ffa718684f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER', 'LOC', 'POH', 'DAT', 'NOH', 'ORG']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55edd0db-81b6-496c-815e-56e5926deddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_sub_ent = []\n",
    "converted_obj_ent = []\n",
    "subject_entity = []\n",
    "object_entity = []\n",
    "for i,j in zip(train_df['subject_entity'], train_df['object_entity']):\n",
    "    # 1. Dict로 변환\n",
    "    i = eval(i)\n",
    "    j = eval(j)\n",
    "    subject_entity.append(i['word'])\n",
    "    object_entity.append(j['word'])\n",
    "    # 2. Punctuation을 넣은 subject_entity, object_entity 추출\n",
    "    # Rule for subject_entity: @ * type * sub_entity @\n",
    "    # Rule for object_entity: # ^ type ^ sub_entity #\n",
    "    i = ' '.join(['@', '*', i['type'], '*', i['word'], '@'])\n",
    "    j = ' '.join(['#', '^', j['type'], '^', j['word'], '#'])\n",
    "    converted_sub_ent.append(i)\n",
    "    converted_obj_ent.append(j)\n",
    "train_df['subject_entity'] = subject_entity\n",
    "train_df['object_entity'] = object_entity\n",
    "train_df['converted_sub_ent'] = converted_sub_ent\n",
    "train_df['converted_obj_ent'] = converted_obj_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0707734-d877-41d9-afbe-4aa28c0c8f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3066\n"
     ]
    }
   ],
   "source": [
    "sub_dup = []\n",
    "for i in range(len(train_df)):\n",
    "    if train_df.iloc[i].sentence.count(train_df.iloc[i].subject_entity) != 1:\n",
    "        # print(i, train_df.iloc[i].subject_entity, train_df.iloc[i].sentence)\n",
    "        sub_dup.append(i)\n",
    "print(len(sub_dup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f675a918-611e-4965-b017-70f49baf4b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1658년, 샤 자한이 병에 걸리자 그의 아들 아우랑제브는 샤 자한을 아그라 성에 죽을때까지 감금했다.', '샤 자한', 716)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(sub_dup)-1)\n",
    "train_df.iloc[sub_dup[idx]].sentence, train_df.iloc[sub_dup[idx]].subject_entity, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8c28ec9-da5f-4816-9984-7e0ec9a46080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([36, 14, 10, 7], ['@', '*', '&', '#'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = ['@', '*', '&', '#']\n",
    "punc_ids = tokenizer.convert_tokens_to_ids(punc)\n",
    "punc_re = tokenizer.convert_ids_to_tokens(punc_ids)\n",
    "punc_ids, punc_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7158f992-e038-4843-87c7-fac749e8d5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa90f635-953f-488e-9435-be2df104c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torchviz in /opt/conda/lib/python3.8/site-packages (0.0.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from torchviz) (1.7.1)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.8/site-packages (from torchviz) (0.20.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch->torchviz) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch->torchviz) (1.19.2)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Reading package lists... Done\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  fontconfig fontconfig-config fonts-dejavu-core fonts-liberation libann0\n",
      "  libcairo2 libcdt5 libcgraph6 libdatrie1 libfontconfig1 libfreetype6 libgd3\n",
      "  libgraphite2-3 libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libharfbuzz0b\n",
      "  libice6 libjbig0 liblab-gamut1 libltdl7 libpango-1.0-0 libpangocairo-1.0-0\n",
      "  libpangoft2-1.0-0 libpathplan4 libpixman-1-0 libsm6 libthai-data libthai0\n",
      "  libtiff5 libwebp6 libxaw7 libxcb-render0 libxcb-shm0 libxmu6 libxpm4\n",
      "  libxrender1 libxt6 x11-common\n",
      "Suggested packages:\n",
      "  gsfonts graphviz-doc libgd-tools\n",
      "The following NEW packages will be installed:\n",
      "  fontconfig fontconfig-config fonts-dejavu-core fonts-liberation graphviz\n",
      "  libann0 libcairo2 libcdt5 libcgraph6 libdatrie1 libfontconfig1 libfreetype6\n",
      "  libgd3 libgraphite2-3 libgts-0.7-5 libgts-bin libgvc6 libgvpr2 libharfbuzz0b\n",
      "  libice6 libjbig0 liblab-gamut1 libltdl7 libpango-1.0-0 libpangocairo-1.0-0\n",
      "  libpangoft2-1.0-0 libpathplan4 libpixman-1-0 libsm6 libthai-data libthai0\n",
      "  libtiff5 libwebp6 libxaw7 libxcb-render0 libxcb-shm0 libxmu6 libxpm4\n",
      "  libxrender1 libxt6 x11-common\n",
      "0 upgraded, 41 newly installed, 0 to remove and 109 not upgraded.\n",
      "Need to get 6958 kB of archives.\n",
      "After this operation, 24.6 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libfreetype6 amd64 2.8.1-2ubuntu2.2 [335 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1041 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 fonts-liberation all 1:1.07.4-7~18.04.1 [822 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig-config all 2.12.6-0ubuntu2 [55.8 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontconfig1 amd64 2.12.6-0ubuntu2 [137 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig amd64 2.12.6-0ubuntu2 [169 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 x11-common all 1:7.7+19ubuntu7.1 [22.5 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libice6 amd64 2:1.0.9-2ubuntu0.18.04.1 [40.7 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsm6 amd64 2:1.2.2-1 [15.8 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libann0 amd64 1.1.2+doc-6 [24.8 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcdt5 amd64 2.40.1-2 [19.6 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcgraph6 amd64 2.40.1-2 [40.8 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjbig0 amd64 2.1-3.1ubuntu0.18.04.1 [27.0 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtiff5 amd64 4.0.9-5ubuntu0.10 [154 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwebp6 amd64 0.6.1-2ubuntu0.18.04.1 [186 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxpm4 amd64 1:3.5.12-1ubuntu0.18.04.2 [34.8 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgd3 amd64 2.2.5-4ubuntu0.5 [119 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4 [150 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpixman-1-0 amd64 0.34.0-2ubuntu0.1 [229 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-render0 amd64 1.13-2~ubuntu18.04 [14.7 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0 amd64 1.13-2~ubuntu18.04 [5600 B]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrender1 amd64 1:0.9.10-1 [18.7 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2 amd64 1.15.10-2ubuntu0.1 [580 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libltdl7 amd64 2.4.6-2 [38.8 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai-data all 0.1.27-2 [133 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdatrie1 amd64 0.2.10-7 [17.8 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libthai0 amd64 0.1.27-2 [18.0 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango-1.0-0 amd64 1.40.14-1ubuntu0.1 [153 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgraphite2-3 amd64 1.3.11-2 [78.7 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libharfbuzz0b amd64 1.7.2-1ubuntu1 [232 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoft2-1.0-0 amd64 1.40.14-1ubuntu0.1 [33.2 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangocairo-1.0-0 amd64 1.40.14-1ubuntu0.1 [20.8 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libpathplan4 amd64 2.40.1-2 [22.6 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6 amd64 2.40.1-2 [601 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvpr2 amd64 2.40.1-2 [169 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 liblab-gamut1 amd64 2.40.1-2 [178 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxt6 amd64 1:1.1.5-1 [160 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxmu6 amd64 2:1.1.2-2 [46.0 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxaw7 amd64 2:1.0.13-1 [173 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu bionic/universe amd64 graphviz amd64 2.40.1-2 [601 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgts-bin amd64 0.7.6+darcs121130-4 [41.3 kB]\n",
      "Fetched 6958 kB in 10s (708 kB/s)                                              \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "(Reading database ... 17022 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libfreetype6_2.8.1-2ubuntu2.2_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.8.1-2ubuntu2.2) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fonts-liberation.\n",
      "Preparing to unpack .../02-fonts-liberation_1%3a1.07.4-7~18.04.1_all.deb ...\n",
      "Unpacking fonts-liberation (1:1.07.4-7~18.04.1) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../03-fontconfig-config_2.12.6-0ubuntu2_all.deb ...\n",
      "Unpacking fontconfig-config (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../04-libfontconfig1_2.12.6-0ubuntu2_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package fontconfig.\n",
      "Preparing to unpack .../05-fontconfig_2.12.6-0ubuntu2_amd64.deb ...\n",
      "Unpacking fontconfig (2.12.6-0ubuntu2) ...\n",
      "Selecting previously unselected package x11-common.\n",
      "Preparing to unpack .../06-x11-common_1%3a7.7+19ubuntu7.1_all.deb ...\n",
      "dpkg-query: no packages found matching nux-tools\n",
      "Unpacking x11-common (1:7.7+19ubuntu7.1) ...\n",
      "Selecting previously unselected package libice6:amd64.\n",
      "Preparing to unpack .../07-libice6_2%3a1.0.9-2ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libice6:amd64 (2:1.0.9-2ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libsm6:amd64.\n",
      "Preparing to unpack .../08-libsm6_2%3a1.2.2-1_amd64.deb ...\n",
      "Unpacking libsm6:amd64 (2:1.2.2-1) ...\n",
      "Selecting previously unselected package libann0.\n",
      "Preparing to unpack .../09-libann0_1.1.2+doc-6_amd64.deb ...\n",
      "Unpacking libann0 (1.1.2+doc-6) ...\n",
      "Selecting previously unselected package libcdt5.\n",
      "Preparing to unpack .../10-libcdt5_2.40.1-2_amd64.deb ...\n",
      "Unpacking libcdt5 (2.40.1-2) ...\n",
      "Selecting previously unselected package libcgraph6.\n",
      "Preparing to unpack .../11-libcgraph6_2.40.1-2_amd64.deb ...\n",
      "Unpacking libcgraph6 (2.40.1-2) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../12-libjbig0_2.1-3.1ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-3.1ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libtiff5:amd64.\n",
      "Preparing to unpack .../13-libtiff5_4.0.9-5ubuntu0.10_amd64.deb ...\n",
      "Unpacking libtiff5:amd64 (4.0.9-5ubuntu0.10) ...\n",
      "Selecting previously unselected package libwebp6:amd64.\n",
      "Preparing to unpack .../14-libwebp6_0.6.1-2ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libwebp6:amd64 (0.6.1-2ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package libxpm4:amd64.\n",
      "Preparing to unpack .../15-libxpm4_1%3a3.5.12-1ubuntu0.18.04.2_amd64.deb ...\n",
      "Unpacking libxpm4:amd64 (1:3.5.12-1ubuntu0.18.04.2) ...\n",
      "Selecting previously unselected package libgd3:amd64.\n",
      "Preparing to unpack .../16-libgd3_2.2.5-4ubuntu0.5_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.5) ...\n",
      "Selecting previously unselected package libgts-0.7-5:amd64.\n",
      "Preparing to unpack .../17-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\n",
      "Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
      "Selecting previously unselected package libpixman-1-0:amd64.\n",
      "Preparing to unpack .../18-libpixman-1-0_0.34.0-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpixman-1-0:amd64 (0.34.0-2ubuntu0.1) ...\n",
      "Selecting previously unselected package libxcb-render0:amd64.\n",
      "Preparing to unpack .../19-libxcb-render0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-render0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxcb-shm0:amd64.\n",
      "Preparing to unpack .../20-libxcb-shm0_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb-shm0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../21-libxrender1_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Selecting previously unselected package libcairo2:amd64.\n",
      "Preparing to unpack .../22-libcairo2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
      "Unpacking libcairo2:amd64 (1.15.10-2ubuntu0.1) ...\n",
      "Selecting previously unselected package libltdl7:amd64.\n",
      "Preparing to unpack .../23-libltdl7_2.4.6-2_amd64.deb ...\n",
      "Unpacking libltdl7:amd64 (2.4.6-2) ...\n",
      "Selecting previously unselected package libthai-data.\n",
      "Preparing to unpack .../24-libthai-data_0.1.27-2_all.deb ...\n",
      "Unpacking libthai-data (0.1.27-2) ...\n",
      "Selecting previously unselected package libdatrie1:amd64.\n",
      "Preparing to unpack .../25-libdatrie1_0.2.10-7_amd64.deb ...\n",
      "Unpacking libdatrie1:amd64 (0.2.10-7) ...\n",
      "Selecting previously unselected package libthai0:amd64.\n",
      "Preparing to unpack .../26-libthai0_0.1.27-2_amd64.deb ...\n",
      "Unpacking libthai0:amd64 (0.1.27-2) ...\n",
      "Selecting previously unselected package libpango-1.0-0:amd64.\n",
      "Preparing to unpack .../27-libpango-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libgraphite2-3:amd64.\n",
      "Preparing to unpack .../28-libgraphite2-3_1.3.11-2_amd64.deb ...\n",
      "Unpacking libgraphite2-3:amd64 (1.3.11-2) ...\n",
      "Selecting previously unselected package libharfbuzz0b:amd64.\n",
      "Preparing to unpack .../29-libharfbuzz0b_1.7.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking libharfbuzz0b:amd64 (1.7.2-1ubuntu1) ...\n",
      "Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
      "Preparing to unpack .../30-libpangoft2-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
      "Preparing to unpack .../31-libpangocairo-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libpathplan4.\n",
      "Preparing to unpack .../32-libpathplan4_2.40.1-2_amd64.deb ...\n",
      "Unpacking libpathplan4 (2.40.1-2) ...\n",
      "Selecting previously unselected package libgvc6.\n",
      "Preparing to unpack .../33-libgvc6_2.40.1-2_amd64.deb ...\n",
      "Unpacking libgvc6 (2.40.1-2) ...\n",
      "Selecting previously unselected package libgvpr2.\n",
      "Preparing to unpack .../34-libgvpr2_2.40.1-2_amd64.deb ...\n",
      "Unpacking libgvpr2 (2.40.1-2) ...\n",
      "Selecting previously unselected package liblab-gamut1.\n",
      "Preparing to unpack .../35-liblab-gamut1_2.40.1-2_amd64.deb ...\n",
      "Unpacking liblab-gamut1 (2.40.1-2) ...\n",
      "Selecting previously unselected package libxt6:amd64.\n",
      "Preparing to unpack .../36-libxt6_1%3a1.1.5-1_amd64.deb ...\n",
      "Unpacking libxt6:amd64 (1:1.1.5-1) ...\n",
      "Selecting previously unselected package libxmu6:amd64.\n",
      "Preparing to unpack .../37-libxmu6_2%3a1.1.2-2_amd64.deb ...\n",
      "Unpacking libxmu6:amd64 (2:1.1.2-2) ...\n",
      "Selecting previously unselected package libxaw7:amd64.\n",
      "Preparing to unpack .../38-libxaw7_2%3a1.0.13-1_amd64.deb ...\n",
      "Unpacking libxaw7:amd64 (2:1.0.13-1) ...\n",
      "Selecting previously unselected package graphviz.\n",
      "Preparing to unpack .../39-graphviz_2.40.1-2_amd64.deb ...\n",
      "Unpacking graphviz (2.40.1-2) ...\n",
      "Selecting previously unselected package libgts-bin.\n",
      "Preparing to unpack .../40-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\n",
      "Unpacking libgts-bin (0.7.6+darcs121130-4) ...\n",
      "Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\n",
      "Setting up libpathplan4 (2.40.1-2) ...\n",
      "Setting up liblab-gamut1 (2.40.1-2) ...\n",
      "Setting up libxcb-render0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libjbig0:amd64 (2.1-3.1ubuntu0.18.04.1) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up libdatrie1:amd64 (0.2.10-7) ...\n",
      "Setting up libtiff5:amd64 (4.0.9-5ubuntu0.10) ...\n",
      "Setting up fonts-liberation (1:1.07.4-7~18.04.1) ...\n",
      "Setting up libfreetype6:amd64 (2.8.1-2ubuntu2.2) ...\n",
      "Setting up libgraphite2-3:amd64 (1.3.11-2) ...\n",
      "Setting up libpixman-1-0:amd64 (0.34.0-2ubuntu0.1) ...\n",
      "Setting up libltdl7:amd64 (2.4.6-2) ...\n",
      "Setting up libann0 (1.1.2+doc-6) ...\n",
      "Setting up libxcb-shm0:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libxpm4:amd64 (1:3.5.12-1ubuntu0.18.04.2) ...\n",
      "Setting up libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Setting up libgts-bin (0.7.6+darcs121130-4) ...\n",
      "Setting up libthai-data (0.1.27-2) ...\n",
      "Setting up x11-common (1:7.7+19ubuntu7.1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up libcdt5 (2.40.1-2) ...\n",
      "Setting up libcgraph6 (2.40.1-2) ...\n",
      "Setting up libwebp6:amd64 (0.6.1-2ubuntu0.18.04.1) ...\n",
      "Setting up fontconfig-config (2.12.6-0ubuntu2) ...\n",
      "Setting up libgvpr2 (2.40.1-2) ...\n",
      "Setting up libharfbuzz0b:amd64 (1.7.2-1ubuntu1) ...\n",
      "Setting up libthai0:amd64 (0.1.27-2) ...\n",
      "Setting up libice6:amd64 (2:1.0.9-2ubuntu0.18.04.1) ...\n",
      "Setting up libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\n",
      "Setting up libsm6:amd64 (2:1.2.2-1) ...\n",
      "Setting up libgd3:amd64 (2.2.5-4ubuntu0.5) ...\n",
      "Setting up libxt6:amd64 (1:1.1.5-1) ...\n",
      "Setting up fontconfig (2.12.6-0ubuntu2) ...\n",
      "Regenerating fonts cache... done.\n",
      "Setting up libcairo2:amd64 (1.15.10-2ubuntu0.1) ...\n",
      "Setting up libxmu6:amd64 (2:1.1.2-2) ...\n",
      "Setting up libpango-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up libxaw7:amd64 (2:1.0.13-1) ...\n",
      "Setting up libpangoft2-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up libpangocairo-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
      "Setting up libgvc6 (2.40.1-2) ...\n",
      "Setting up graphviz (2.40.1-2) ...\n",
      "Processing triggers for systemd (237-3ubuntu10.52) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n"
     ]
    }
   ],
   "source": [
    "! pip install torchviz\n",
    "! apt-get install -y graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f94def-0776-4a62-815a-2e1fe26e0de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at klue/roberta-small were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=30, bias=True)\n",
      "  )\n",
      ") RobertaModel(\n",
      "  (embeddings): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RobertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): RobertaPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoModel\n",
    "model_1 = AutoModelForSequenceClassification.from_pretrained('klue/roberta-small', num_labels=30)\n",
    "model_1.to('cpu')\n",
    "\n",
    "model_2 = AutoModel.from_pretrained('klue/roberta-small')\n",
    "print(model_1, model_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "214f4035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,   168, 30985, 14451,  7088,  4586,   169,   793,     7,  8373,\n",
       "         14113,  2234,     7,  1504,  1363,  2088,    36, 29830,    36,   543,\n",
       "         14879,  2440,  6711,   170, 21406, 26713,  2076, 25145,  5749,   171,\n",
       "          1421,   818,  2073,  4388,  2062,    18,     3,     0,     0,     0],\n",
       "        [    2,  6409,  2052,  4568,  2179,  6417,  2044,  2315,  2481,   100,\n",
       "             7,  5605,  2250,  2481,     7,   100,    36,  3772,  2139,  2267,\n",
       "          2481,    36,  1504, 16489,   711,  2170, 12827,  2097,  8646,  2481,\n",
       "            12, 15283,    13,  3603,  1528,  2554,  2065,  4538,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ec5b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d01c000-acbf-45ad-a89d-762386ff8a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "out = model_2(k.input_ids)\n",
    "print(out.pooler_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cec51afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 30])\n"
     ]
    }
   ],
   "source": [
    "n = torch.nn.Linear(768, 30)\n",
    "out2 = n(out.pooler_output)\n",
    "print(out2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d51b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d705a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7225a7ec-0377-4d38-8271-0a31cb13522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_relation': 0, 'org:top_members/employees': 1, 'org:members': 2, 'org:product': 3, 'per:title': 4, 'org:alternate_names': 5, 'per:employee_of': 6, 'org:place_of_headquarters': 7, 'per:product': 8, 'org:number_of_employees/members': 9, 'per:children': 10, 'per:place_of_residence': 11, 'per:alternate_names': 12, 'per:other_family': 13, 'per:colleagues': 14, 'per:origin': 15, 'per:siblings': 16, 'per:spouse': 17, 'org:founded': 18, 'org:political/religious_affiliation': 19, 'org:member_of': 20, 'per:parents': 21, 'org:dissolved': 22, 'per:schools_attended': 23, 'per:date_of_death': 24, 'per:date_of_birth': 25, 'per:place_of_birth': 26, 'per:place_of_death': 27, 'org:founded_by': 28, 'per:religion': 29}\n"
     ]
    }
   ],
   "source": [
    "with open('./code/dict_label_to_num.pkl', 'rb') as f:\n",
    "    dict_label_to_num = pickle.load(f)\n",
    "    print(dict_label_to_num)\n",
    "# for v in label:\n",
    "#     num_label.append(dict_label_to_num[v])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
