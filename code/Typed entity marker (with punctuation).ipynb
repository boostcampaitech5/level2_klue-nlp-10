{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b009bde-b219-4f2b-8f2a-1ce779966fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "path = '../dataset/train/train_no_dup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18faf4fa-aa92-40e5-9e3e-96333096ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' csv파일을 불러와 subject_entity & object_entity word를 불러와 \n",
    "    Typed entity marker(with punctuation)처리를 해주는 과정이다. '''\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "\n",
    "    data = pd.read_csv(path)\n",
    "\n",
    "    sub_entity, sub_type = [], []\n",
    "    obj_entity, obj_type = [], []\n",
    "    sub_idx, obj_idx = [], []\n",
    "    sentence = []\n",
    "\n",
    "    for i, [x, y, z] in enumerate(zip(data['subject_entity'], data['object_entity'], data['sentence'])):\n",
    "        sub_typ = x[1:-1].split(':')[-1].split('\\'')[-2]\n",
    "        obj_typ = y[1:-1].split(':')[-1].split('\\'')[-2]\n",
    "\n",
    "        for idx_i in range(len(x)):\n",
    "            if x[idx_i: idx_i + 9] == 'start_idx':\n",
    "                sub_start = int(x[idx_i+12:].split(',')[0].strip())\n",
    "            if x[idx_i: idx_i+7] == 'end_idx':\n",
    "                sub_end = int(x[idx_i+10:].split(',')[0].strip())\n",
    "\n",
    "            if y[idx_i: idx_i + 9] == 'start_idx':\n",
    "                obj_start = int(y[idx_i+12:].split(',')[0].strip())\n",
    "            if y[idx_i: idx_i+7] == 'end_idx':\n",
    "                obj_end = int(y[idx_i+10:].split(',')[0].strip())\n",
    "\n",
    "        sub_i = [sub_start, sub_end]\n",
    "        obj_i = [obj_start, obj_end]\n",
    "\n",
    "        sub_entity.append(z[sub_i[0]: sub_i[1]+1])\n",
    "        obj_entity.append(z[obj_i[0]: obj_i[1]+1])\n",
    "        sub_type.append(sub_typ)\n",
    "        sub_idx.append(sub_i)\n",
    "        obj_type.append(obj_typ)\n",
    "        obj_idx.append(obj_i)\n",
    "\n",
    "        if sub_i[0] < obj_i[0]:\n",
    "            z = z[:sub_i[0]] + '@*'+sub_typ+'*' + \\\n",
    "                z[sub_i[0]: sub_i[1]+1] + '@' + z[sub_i[1]+1:]\n",
    "            z = z[:obj_i[0]+7] + '#^' + obj_typ + '^' + \\\n",
    "                z[obj_i[0]+7: obj_i[1]+8] + '#' + z[obj_i[1]+8:]\n",
    "        else:\n",
    "            z = z[:obj_i[0]] + '#^' + obj_typ + '^' + \\\n",
    "                z[obj_i[0]: obj_i[1]+1] + '#' + z[obj_i[1]+1:]\n",
    "            z = z[:sub_i[0]+7] + '@*'+sub_typ+'*' + \\\n",
    "                z[sub_i[0]+7: sub_i[1]+8] + '@' + z[sub_i[1]+8:]\n",
    "\n",
    "        sentence.append(z)\n",
    "\n",
    "    df = pd.DataFrame({'id': data['id'], 'sentence': sentence, 'subject_entity': sub_entity, 'object_entity': obj_entity,\n",
    "                      'subject_type': sub_type, 'object_type': obj_type, 'label': data['label'],\n",
    "                       'subject_idx': sub_idx, 'object_idx': obj_idx})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f658cfb7-aba6-4b89-b17c-4eb95a55deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Typed entity marker(with punctuation)처리된 data를 token화 하고 concat '''\n",
    "\n",
    "\n",
    "def tokenized_dataset(dataset, tokenizer):\n",
    "    # tokenizer에 따라 sentence를 tokenizing\n",
    "\n",
    "    concat_entity = []\n",
    "    for e01, e02, t01, t02 in zip(dataset['subject_entity'], dataset['object_entity'], dataset['subject_type'], dataset['object_type']):\n",
    "        temp = '@*' + t01 + '*' + e01 + '@' + '와' + \\\n",
    "            '#^' + t02 + '^' + e02 + '#' + '의 관계'\n",
    "        concat_entity.append(temp)\n",
    "\n",
    "    tokenized_sentences = tokenizer(\n",
    "        concat_entity,\n",
    "        list(dataset['sentence']),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3714bd27-4e9b-4057-9ca3-d5c59a885819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>subject_type</th>\n",
       "      <th>object_type</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>object_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 #^PER^조지 해리슨#이 쓰고 @*ORG*비틀즈@가 196...</td>\n",
       "      <td>비틀즈</td>\n",
       "      <td>조지 해리슨</td>\n",
       "      <td>ORG</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>[24, 26]</td>\n",
       "      <td>[13, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·#^ORG^대안신당#·@*ORG*민주평화당@이 우여곡절 끝...</td>\n",
       "      <td>민주평화당</td>\n",
       "      <td>대안신당</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>[19, 23]</td>\n",
       "      <td>[14, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>K리그2에서 성적 1위를 달리고 있는 @*ORG*광주FC@는 지난 26일 #^ORG...</td>\n",
       "      <td>광주FC</td>\n",
       "      <td>한국프로축구연맹</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORG</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>[21, 24]</td>\n",
       "      <td>[34, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>균일가 생활용품점 (주)@*ORG*아성다이소@(대표 #^PER^박정부#)는 코로나1...</td>\n",
       "      <td>아성다이소</td>\n",
       "      <td>박정부</td>\n",
       "      <td>ORG</td>\n",
       "      <td>PER</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>[13, 17]</td>\n",
       "      <td>[22, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>#^DAT^1967#년 프로 야구 드래프트 1순위로 @*ORG*요미우리 자이언츠@에...</td>\n",
       "      <td>요미우리 자이언츠</td>\n",
       "      <td>1967</td>\n",
       "      <td>ORG</td>\n",
       "      <td>DAT</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>[22, 30]</td>\n",
       "      <td>[0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32423</th>\n",
       "      <td>32465</td>\n",
       "      <td>한국당은 7일 오전 9시부터 오후 5시까지 진행된 원내대표 및 정책위의장 후보자 등...</td>\n",
       "      <td>유기준</td>\n",
       "      <td>부산 서구·동구</td>\n",
       "      <td>PER</td>\n",
       "      <td>LOC</td>\n",
       "      <td>per:employee_of</td>\n",
       "      <td>[93, 95]</td>\n",
       "      <td>[100, 107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32424</th>\n",
       "      <td>32466</td>\n",
       "      <td>법포는 다시 @*PER*최시형@, 서병학, #^PER^손병희# 직계인 북접과 다시 ...</td>\n",
       "      <td>최시형</td>\n",
       "      <td>손병희</td>\n",
       "      <td>PER</td>\n",
       "      <td>PER</td>\n",
       "      <td>per:colleagues</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>[17, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32425</th>\n",
       "      <td>32467</td>\n",
       "      <td>@*ORG*완도군@(군수 #^PER^신우철#)이 국토교통부에서 실시한 '2019 교...</td>\n",
       "      <td>완도군</td>\n",
       "      <td>신우철</td>\n",
       "      <td>ORG</td>\n",
       "      <td>PER</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[7, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32426</th>\n",
       "      <td>32468</td>\n",
       "      <td>중앙일보, @*ORG*JTBC@ 회장을 지낸 이후 #^ORG^중앙홀딩스# 회장, 재...</td>\n",
       "      <td>JTBC</td>\n",
       "      <td>중앙홀딩스</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>[21, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32427</th>\n",
       "      <td>32469</td>\n",
       "      <td>@*ORG*화순군@(군수 #^PER^구충곤#)은 17일 동면의 이장 20여 명이 코...</td>\n",
       "      <td>화순군</td>\n",
       "      <td>구충곤</td>\n",
       "      <td>ORG</td>\n",
       "      <td>PER</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[7, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32428 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           sentence   \n",
       "0          0  〈Something〉는 #^PER^조지 해리슨#이 쓰고 @*ORG*비틀즈@가 196...  \\\n",
       "1          1  호남이 기반인 바른미래당·#^ORG^대안신당#·@*ORG*민주평화당@이 우여곡절 끝...   \n",
       "2          2  K리그2에서 성적 1위를 달리고 있는 @*ORG*광주FC@는 지난 26일 #^ORG...   \n",
       "3          3  균일가 생활용품점 (주)@*ORG*아성다이소@(대표 #^PER^박정부#)는 코로나1...   \n",
       "4          4  #^DAT^1967#년 프로 야구 드래프트 1순위로 @*ORG*요미우리 자이언츠@에...   \n",
       "...      ...                                                ...   \n",
       "32423  32465  한국당은 7일 오전 9시부터 오후 5시까지 진행된 원내대표 및 정책위의장 후보자 등...   \n",
       "32424  32466  법포는 다시 @*PER*최시형@, 서병학, #^PER^손병희# 직계인 북접과 다시 ...   \n",
       "32425  32467  @*ORG*완도군@(군수 #^PER^신우철#)이 국토교통부에서 실시한 '2019 교...   \n",
       "32426  32468  중앙일보, @*ORG*JTBC@ 회장을 지낸 이후 #^ORG^중앙홀딩스# 회장, 재...   \n",
       "32427  32469  @*ORG*화순군@(군수 #^PER^구충곤#)은 17일 동면의 이장 20여 명이 코...   \n",
       "\n",
       "      subject_entity object_entity subject_type object_type   \n",
       "0                비틀즈        조지 해리슨          ORG         PER  \\\n",
       "1              민주평화당          대안신당          ORG         ORG   \n",
       "2               광주FC      한국프로축구연맹          ORG         ORG   \n",
       "3              아성다이소           박정부          ORG         PER   \n",
       "4          요미우리 자이언츠          1967          ORG         DAT   \n",
       "...              ...           ...          ...         ...   \n",
       "32423            유기준      부산 서구·동구          PER         LOC   \n",
       "32424            최시형           손병희          PER         PER   \n",
       "32425            완도군           신우철          ORG         PER   \n",
       "32426           JTBC         중앙홀딩스          ORG         ORG   \n",
       "32427            화순군           구충곤          ORG         PER   \n",
       "\n",
       "                           label subject_idx  object_idx  \n",
       "0                    no_relation    [24, 26]    [13, 18]  \n",
       "1                    no_relation    [19, 23]    [14, 17]  \n",
       "2                  org:member_of    [21, 24]    [34, 41]  \n",
       "3      org:top_members/employees    [13, 17]    [22, 24]  \n",
       "4                    no_relation    [22, 30]      [0, 3]  \n",
       "...                          ...         ...         ...  \n",
       "32423            per:employee_of    [93, 95]  [100, 107]  \n",
       "32424             per:colleagues      [7, 9]    [17, 19]  \n",
       "32425  org:top_members/employees      [0, 2]      [7, 9]  \n",
       "32426                no_relation      [6, 9]    [21, 25]  \n",
       "32427  org:top_members/employees      [0, 2]      [7, 9]  \n",
       "\n",
       "[32428 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = load_data(path)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83bbb6e8-ba50-41c5-812f-8797e9e4a4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '@', '*', 'O', '##R', '##G', '*', '비틀즈', '@', '와', '#', '^', 'PER', '^', '조지', '해리', '##슨', '#', '의', '관계', '[SEP]', '〈', 'So', '##me', '##th', '##ing', '〉', '는', '#', '^', 'PER', '^', '조지', '해리', '##슨', '#', '이', '쓰', '##고', '@', '*', 'O', '##R', '##G', '*', '비틀즈', '@', '가', '1969', '##년', '앨범', '《', 'Ab', '##be', '##y', 'Ro', '##ad', '》', '에', '담', '##은', '노래', '##다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "==================================================\n",
      "[0, 36, 14, 51, 2107, 2341, 14, 29830, 36, 1453, 7, 65, 21639, 65, 8373, 14113, 2234, 7, 1503, 3654, 2, 168, 30985, 14451, 7088, 4586, 169, 793, 7, 65, 21639, 65, 8373, 14113, 2234, 7, 1504, 1363, 2088, 36, 14, 51, 2107, 2341, 14, 29830, 36, 543, 14879, 2440, 6711, 170, 21406, 26713, 2076, 25145, 5749, 171, 1421, 818, 2073, 4388, 2062, 18, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "==================================================\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "==================================================\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "''' 토큰화 후 첫 index로 잘 되었는지 확인한다.\n",
    "패딩된 token 확인, ids 확인, attention_mask 확인, type_ids 확인 '''\n",
    "\n",
    "MODEL_NAME = \"klue/roberta-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenized_train = tokenized_dataset(train_df, tokenizer)\n",
    "\n",
    "print(tokenized_train[0].tokens)\n",
    "print('='*50)\n",
    "print(tokenized_train[0].ids)\n",
    "print('='*50)\n",
    "print(tokenized_train[0].attention_mask)\n",
    "print('='*50)\n",
    "print(tokenized_train[0].type_ids)\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335b863-b53f-43f0-a4bb-a0c7ecd75391",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 위의 과정을 본 코드에서는 train.py에서 처리 해 주는데 load_data.py에서 불러와\n",
    "train_dataset = load_data(\"../dataset/train/train_no_dup.csv\")로 간단하게 처리한 후\n",
    "tokenized_train = tokenized_dataset(augmented_train_dataset, tokenizer)로 사용한다. '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
